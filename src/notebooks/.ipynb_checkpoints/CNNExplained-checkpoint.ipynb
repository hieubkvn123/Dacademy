{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io ### New library - scikit-image - Install : pip3 install scikit-image ###\n",
    "from skimage import color\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "### PyTorch dependencies ###\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms # Preprocessing module from torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Convolutional Neural Network (CNN)\n",
    "## What is Convolutional Neural Network \n",
    "* A CNN is a type of neural network that works best for the image processing task. The word \"convolution\" is originated from the filtering process of the network. An image is a complex structure that requires the neural network to pick up only the necessary features. Hence, unlike the normal artificial neural network, images are filtered before being fed into the fully connected layer.\n",
    "![CNN illustration](https://miro.medium.com/max/1400/1*uAeANQIOQPqWZnnuH-VEyw.jpeg)\n",
    "* Illustration video : [Youtube link](https://www.youtube.com/watch?v=x_VrgWTKkiM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How convolutional layer works\n",
    "![Conv layer](https://mandroid6.github.io/images/Convolution_schematic.gif)\n",
    "* A convolutional layer consist of a learnable kernel that is used to extract information from an image. A kernel is basically a matrix that slides across an image from left to right, from top to bottom. This kernel will perform element-wise multiplication on the pixels that it came across and sum the multiplications up as the result. These kernel is **learnable**, which means that they can be updated during training.\n",
    "* The concept of a kernel is also used in computer vision to extract the edges of an image. For example (sobel, morphological operations, ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of convolutional layer in PyTorch\n",
    "* In this example we will look at some of the predefined kernels used in image processing just to see how features are extracted by the convolutional layer. Two of the commonly used kernels are the vertical feature extraction kernel and horizontal feature extraction kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the vertical kernel\n",
    "kernel_ver = np.array([[1, 0, -1],[2,0,-2],[1,0,-1]])\n",
    "conv1 = nn.Conv2d(in_channels=3, out_channels=1, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "conv1.weight = nn.Parameter(torch.from_numpy(kernel_ver).float().unsqueeze(0).unsqueeze(0))\n",
    "\n",
    "# Create the horizontal kernel (Basically transpose of vertical kernel)\n",
    "kernel_hor = kernel_ver.transpose()\n",
    "conv2 = nn.Conv2d(in_channels=3, out_channels=1, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "conv2.weight = nn.Parameter(torch.from_numpy(kernel_hor).float().unsqueeze(0).unsqueeze(0))\n",
    "\n",
    "fig, ax = plt.subplots(1,3, figsize=(15,5))\n",
    "\n",
    "# Load image from url and convert to gray scale\n",
    "image = io.imread('https://media.springernature.com/w300/springer-static/image/art%3A10.1038%2Fnature.2012.9751/MediaObjects/41586_2012_Article_BFnature20129751_Figa_HTML.jpg')\n",
    "image = color.rgb2gray(image)\n",
    "ax[0].imshow(image, cmap='gray')\n",
    "ax[0].set_title('Original image')\n",
    "\n",
    "# Convert the image to Float Tensor and reshape to pytorch image data format\n",
    "image = torch.FloatTensor(image)\n",
    "image = image.reshape(-1, 1, image.shape[0], image.shape[1])\n",
    "\n",
    "# Pass the image through the convolutional layer then show the result\n",
    "conv_image = conv1(image) # Pass the image thru the conv layer\n",
    "conv_image = conv_image.detach().numpy() # Detach the result from grad mode and convert to numpy\n",
    "conv_image = conv_image.reshape(conv_image.shape[2], conv_image.shape[3]) # Reshape the image back to normal shape\n",
    "ax[1].imshow(conv_image, cmap='gray') \n",
    "ax[1].set_title('Vertical features of the image')\n",
    "\n",
    "# Pass the image through the convolutional layer then show the result\n",
    "conv_image = conv2(image)\n",
    "conv_image = conv_image.detach().numpy()\n",
    "conv_image = conv_image.reshape(conv_image.shape[2], conv_image.shape[3])\n",
    "ax[2].imshow(conv_image, cmap='gray')\n",
    "ax[2].set_title('Horizontal features of the image')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How maxpooling layer works\n",
    "![Max pooling](https://nico-curti.github.io/NumPyNet/NumPyNet/images/maxpool.gif)\n",
    "* Max-pooling layer is similar to the convolutional layer in such a way that it also has sliding kernel. However, this kernel is **not learnable** and it will not take the sum of element wise multiplication. Instead, the max pooling layer takes the maximum value. THe purpose of this layer is to downsample the output of the convolutional layer to firstly, improve the computational performance by downsampling data and secondly, to generalize data so that the network only pick up the most important features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of max pooling\n",
    "* After down-sample the output from the convolutional layer, you should see that the dimension of the outputs decrease by a half."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the vertical kernel\n",
    "kernel_ver = np.array([[1, 0, -1],[2,0,-2],[1,0,-1]])\n",
    "conv1 = nn.Conv2d(in_channels=3, out_channels=1, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "conv1.weight = nn.Parameter(torch.from_numpy(kernel_ver).float().unsqueeze(0).unsqueeze(0))\n",
    "\n",
    "# Create a max-pooling layer\n",
    "maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "fig, ax = plt.subplots(1,3, figsize=(15,5))\n",
    "\n",
    "# Load image from url and convert to gray scale\n",
    "image = io.imread('https://media.springernature.com/w300/springer-static/image/art%3A10.1038%2Fnature.2012.9751/MediaObjects/41586_2012_Article_BFnature20129751_Figa_HTML.jpg')\n",
    "image = color.rgb2gray(image)\n",
    "ax[0].imshow(image, cmap='gray')\n",
    "ax[0].set_title('Original image')\n",
    "\n",
    "# Convert the image to Float Tensor and reshape to pytorch image data format\n",
    "image = torch.FloatTensor(image)\n",
    "image = image.reshape(-1, 1, image.shape[0], image.shape[1])\n",
    "\n",
    "# Pass the image through the convolutional layer then show the result\n",
    "conv_image = conv1(image) # Pass the image thru the conv layer\n",
    "# Pass the output of the convolutional layer through the max pooling layer\n",
    "maxpool_output = maxpool(conv_image)\n",
    "\n",
    "conv_image = conv_image.detach().numpy() # Detach the result from grad mode and convert to numpy\n",
    "conv_image = conv_image.reshape(conv_image.shape[2], conv_image.shape[3]) # Reshape the image back to normal shape\n",
    "\n",
    "maxpool_output = maxpool_output.detach().numpy() # Detach the result from grad mode and convert to numpy\n",
    "maxpool_output = maxpool_output.reshape(maxpool_output.shape[2], maxpool_output.shape[3]) # Reshape the image back to normal shape\n",
    "\n",
    "ax[1].imshow(conv_image, cmap='gray') \n",
    "ax[1].set_title('Vertical features of the image')\n",
    "\n",
    "ax[2].imshow(maxpool_output, cmap='gray')\n",
    "ax[2].set_title('Downsampled output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
